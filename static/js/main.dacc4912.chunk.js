(this.webpackJsonpbase=this.webpackJsonpbase||[]).push([[4],{12:function(e,t,a){"use strict";a.d(t,"e",(function(){return i})),a.d(t,"c",(function(){return n})),a.d(t,"d",(function(){return o})),a.d(t,"b",(function(){return s})),a.d(t,"a",(function(){return l})),a.d(t,"f",(function(){return r}));var i,n,o,s,r,l,d=Object({NODE_ENV:"production",PUBLIC_URL:"",WDS_SOCKET_HOST:void 0,WDS_SOCKET_PATH:void 0,WDS_SOCKET_PORT:void 0,FAST_REFRESH:!0,REACT_APP_TEAM_PUBLICATIONS:'[{"_id":"6146e525aa81560b29a40b3e","authors":["Xiao Chen","Wanli Chen","Kui Liu","Chunyang Chen","Li Li"],"title":"A comparative study of smartphone and smartwatch apps","link":"","description":"Despite that our community has spent numerous efforts on analyzing mobile apps, there is no study proposed for characterizing the relationship between smartphone and smartwatch apps. To fill this gap, we present to the community a comparative study of smartphone and smartwatch apps, aiming at understanding the status quo of cross-phone/watch apps. Specifically, in this work, we first collect a set of cross-phone/watch app pairs and then experimentally look into them to explore their similarities or dissimilarities from different perspectives. Experimental results show that (1) Approximately, up to 40% of resource files, 30% of code methods are reused between smartphone/watch app pairs,(2) Smartphone apps may require more than twice as many as permissions and adopt more than five times as many as user interactions than their watch counterparts, and (3) Smartwatch apps can be released as either\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Book","categoryTitle":"Proceedings of the 36th Annual ACM Symposium on Applied Computing","pages":"1484-1493","publisher":"","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b37","authors":["Sen Chen","Chunyang Chen","Lingling Fan","Mingming Fan","Xian Zhan","Yang Liu"],"title":"Accessible or Not An Empirical Investigation of Android App Accessibility","link":"","description":"Mobile apps provide new opportunities to people with disabilities to act independently in the world. Following the law of the US, EU, mobile OS vendors such as Google and Apple have included accessibility features in their mobile systems and provide a set of guidelines and toolsets for ensuring mobile app accessibility. Motivated by this trend, researchers have conducted empirical studies by using the inaccessibility issue rate of each page (i.e., screen level) to represent the characteristics of mobile app accessibility. However, there still lacks an empirical investigation directly focusing on the issues themselves (i.e., issue level) to unveil more fine-grained findings, due to the lack of an effective issue detection method and a relatively comprehensive dataset of issues. To fill in this literature gap, we first propose an automated app page exploration tool, named Xbot, to facilitate app accessibility testing and\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Journal","categoryTitle":"IEEE Transactions on Software Engineering","pages":"","publisher":"IEEE","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.162Z","updatedAt":"2021-09-19T07:22:13.162Z","year":2021},{"_id":"6146e525aa81560b29a40b3d","authors":["Sidong Feng","Suyu Ma","Jinzhong Yu","Chunyang Chen","TingTing Zhou","Yankun Zhen"],"title":"Auto-icon: An automated code generation tool for icon designs assisting in ui development","link":"","description":"Approximately 50% of development resources are devoted to UI development tasks [8]. Occupied a large proportion of development resources, developing icons can be a time-consuming task, because developers need to consider not only effective implementation methods but also easy-to-understand descriptions. In this study, we define 100 icon classes through an iterative open coding for the existing icon design sharing website. Based on a deep learning model and computer vision methods, we propose an approach to automatically convert icon images to fonts with descriptive labels, thereby reducing the laborious manual effort for developers and facilitating UI development. We quantitatively evaluate the quality of our method in the real world UI development environment and demonstrate that our method offers developers accurate, efficient, readable, and usable code for icon images, in terms of saving 65.2\xa0\u2026","yearPublished":"2021","citedBy":120211,"category":{"type":"Book","categoryTitle":"26th International Conference on Intelligent User Interfaces","pages":"59-69","publisher":"","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b40","authors":["Kaibo Cao","Chunyang Chen","Sebastian Baltes","Christoph Treude","Xiang Chen"],"title":"Automated Query Reformulation for Efficient Search based on Query Logs From Stack Overflow","link":"https://arxiv.org/pdf/2102.00826","description":"As a popular Q&A site for programming, Stack Overflow is a treasure for developers. However, the amount of questions and answers on Stack Overflow make it difficult for developers to efficiently locate the information they are looking for. There are two gaps leading to poor search results: the gap between the user\u2019s intention and the textual query, and the semantic gap between the query and the post content. Therefore, developers have to constantly reformulate their queries by correcting misspelled words, adding limitations to certain programming languages or platforms, etc. As query reformulation is tedious for developers, especially for novices, we propose an automated software-specific query reformulation approach based on deep learning. With query logs provided by Stack Overflow, we construct a large-scale query reformulation corpus, including the original queries and corresponding reformulated ones\xa0\u2026","yearPublished":"2021","citedBy":620216,"category":{"type":"Conference","categoryTitle":"43rd International Conference on Software Engineering (ICSE)","pages":"","publisher":"","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.164Z","updatedAt":"2021-09-19T07:22:13.164Z","year":2021},{"_id":"6146e525aa81560b29a40b3b","authors":["Junjie Wang","Ye Yang","Song Wang","Chunyang Chen","Dandan Wang","Qing Wang"],"title":"Context-aware Personalized Crowdtesting Task Recommendation","link":"","description":"Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker\'s failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers\' perspectives. We motivate this study through a pilot study, revealing the large portion (74\\\\%) of unpaid crowdworkers\'\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Journal","categoryTitle":"IEEE Transactions on Software Engineering","pages":"","publisher":"IEEE","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b3f","authors":["Han Wang","Chunyang Chen","Zhenchang Xing","John Grundy"],"title":"DiffTech: Differencing Similar Technologies from Crowd-Scale Comparison Discussions","link":"","description":"Developers use different technologies for many software development tasks. However, when faced with several technologies with comparable functionalities, it is not easy to select the most appropriate one, as trial and error comparisons among such technologies are time-consuming. Instead, developers can resort to expert articles, read official documents or ask questions in Q&A sites. However, it still remains difficult to get a comprehensive comparison as online information is often fragmented or contradictory. To overcome these limitations, we propose the DiffTech system that exploits crowdsourced discussions from Stack Overflow, and assists technology comparison with an informative summary of different aspects. We first build a large database of comparable technologies in software engineering by mining tags in Stack Overflow. We then locate comparative sentences about comparable technologies with\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Journal","categoryTitle":"IEEE Transactions on Software Engineering","pages":"","publisher":"IEEE","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.164Z","updatedAt":"2021-09-19T07:22:13.164Z","year":2021},{"_id":"6146e525aa81560b29a40b3a","authors":["Bo Yang","Zhenchang Xing","Xin Xia","Chunyang Chen","Deheng Ye","Shanping Li"],"title":"Don\u2019t Do That! Hunting Down Visual Design Smells in Complex UIs against Design Guidelines","link":"https://xin-xia.github.io/publication/icse213.pdf","description":"Just like code smells in source code, UI design has visual design smells. We study 93 don\u2019t-do-that guidelines in the Material Design, a complex design system created by Google. We find that these don\u2019t-guidelines go far beyond UI aesthetics, and involve seven general design dimensions (layout, typography, iconography, navigation, communication, color, and shape) and four component design aspects (anatomy, placement, behavior, and usage). Violating these guidelines results in visual design smells in UIs (or UI design smells). In a study of 60,756 UIs of 9,286 Android apps, we find that 7,497 UIs of 2,587 apps have at least one violation of some Material Design guidelines. This reveals the lack of developer training and tool support to avoid UI design smells. To fill this gap, we design an automated UI design smell detector (UIS-Hunter) that extracts and validates multi-modal UI information (component\xa0\u2026","yearPublished":"2021","citedBy":120211,"category":{"type":"Conference","categoryTitle":"2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)","pages":"761-772","publisher":"IEEE","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b3c","authors":["Qiuyuan Chen","Chunyang Chen","Safwat Hassan","Zhengchang Xing","Xin Xia","Ahmed E Hassan"],"title":"How Should I Improve the UI of My App? A Study of User Reviews of Popular Apps in the Google Play","link":"","description":"UI (User Interface) is an essential factor influencing users\u2019 perception of an app. However, it is hard for even professional designers to determine if the UI is good or not for end-users. Users\u2019 feedback (e.g., user reviews in the Google Play) provides a way for app owners to understand how the users perceive the UI. In this article, we conduct an in-depth empirical study to analyze the UI issues of mobile apps. In particular, we analyze more than 3M UI-related reviews from 22,199 top free-to-download apps and 9,380 top non-free apps in the Google Play Store. By comparing the rating of UI-related reviews and other reviews of an app, we observe that UI-related reviews have lower ratings than other reviews. By manually analyzing a random sample of 1,447 UI-related reviews with a 95% confidence level and a 5% interval, we identify 17 UI-related issues types that belong to four categories (i.e., \u201cAppearance\xa0\u2026","yearPublished":"2021","citedBy":320213,"category":{"type":"Journal","categoryTitle":"ACM Transactions on Software Engineering and Methodology (TOSEM)","pages":"1-38","publisher":"ACM","volume":"30","issue":"3"},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b38","authors":["Yuhui Su","Zhe Liu","Chunyang Chen","Junjie Wang","Qing Wang"],"title":"OwlEyes-online: a fully automated platform for detecting and localizing UI display issues","link":"https://arxiv.org/pdf/2107.02364","description":"Graphical User Interface (GUI) provides visual bridges between software apps and end users. However, due to the compatibility of software or hardware, UI display issues such as text overlap, blurred screen, image missing always occur during GUI rendering on different devices. Because these UI display issues can be found directly by human eyes, in this paper, we implement an online UI display issue detection tool OwlEyes-Online, which provides a simple and easy-to-use platform for users to realize the automatic detection and localization of UI display issues. The OwlEyes-Online can automatically run the app and get its screenshots and XML files, and then detect the existence of issues by analyzing the screenshots. In addition, OwlEyes-Online can also find the detailed area of the issue in the given screenshots to further remind developers. Finally, OwlEyes-Online will automatically generate test reports with UI\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Book","categoryTitle":"Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","pages":"1500-1504","publisher":"","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021},{"_id":"6146e525aa81560b29a40b39","authors":["Bo Yang","Zhenchang Xing","Xin Xia","Chunyang Chen","Deheng Ye","Shanping Li"],"title":"UIS-Hunter: Detecting UI Design Smells in Android Apps","link":"https://xin-xia.github.io/publication/icse217.pdf","description":"Similar to code smells in source code, UI design has visual design smells that indicate violations of good UI design guidelines. UI design guidelines constitute design systems for a vast variety of products, platforms, and services. Following a design system, developers can avoid common design issues and pitfalls. However, a design system is often complex, involving various design dimensions and numerous UI components. Lack of concerns on GUI visual effect results in little support for detecting UI design smells that violate the design guidelines in a complex design system. In this paper, we propose an automated UI design smell detector named UIS-Hunter (UI design Smell Hunter). The tool is able to (i) automatically process UI screenshots or prototype files to detect UI design smells and generate reports, (ii) highlight the violated UI regions and list the material design guidelines that the found design smells\xa0\u2026","yearPublished":"2021","citedBy":null,"category":{"type":"Conference","categoryTitle":"2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","pages":"89-92","publisher":"IEEE","volume":"","issue":""},"teamId":"61028e57ff2069b3c154c50b","__v":0,"createdAt":"2021-09-19T07:22:13.163Z","updatedAt":"2021-09-19T07:22:13.163Z","year":2021}]',REACT_APP_TEAM_MEMBERS:'[{"_id":"6118fae5e01bfad1e9bcf8ac","fullName":"Kunj Dave","position":"Chairman","summary":"Mr. Dave was a previous Youtuber who then transitioned into Software Development and no chairs the team in their development for world\'s first multi-AI algorithm"}]',REACT_APP_TEAM_INFO:'{"_id":"61028e57ff2069b3c154c50b","email":"Fred@Nurk.com","teamName":"Fred","orgName":"Nurk"}',REACT_APP_TEAM_ACHIEVEMENTS:'[{"_id":"614d1bf3e869f71e26ccdb7e","title":"Example","yearAwarded":2021,"description":"Example achievment","teamId":"61028e57ff2069b3c154c50b","__v":0}]',REACT_APP_TEAM_HOMEPAGE:'{"aboutUs":["WWF was founded in Morges, Switzerland, in 1961. At first its goal was simply to raise funds to support other conservation organizations.","One of the first organizations WWF supported was the International Union for the Conservation of Nature (IUCN). The funds they gave IUCN helped it produce its first Red List of Threatened Species in 1964. The Red List has been continually updated with the latest scientific data on threatened species, with nearly 160,000 species assessed so far. Of these, more than 32,000 species are now listed as threatened with extinction, including 41% of all amphibians, 26% of mammals and 14% of birds. To best use the money it collects, WWF uses data like this to identify the most endangered species and support NGOs that are working to protect them.","In the 1970s, WWF also began doing projects of its own. In 1973 it bought 37,000 acres of land near Lake Nakuru in Kenya, an important habitat for many birds including flamingos. It also helped to establish nature reserves in Costa Rica, Colombia, Nepal and Mexico, as well as establishing projects in Africa to help protect critically endangered species like the white rhino and the mountain gorilla.","In the 1980s WWF began several new projects including the Lumparda Elephant Project that led to a sharp decline in the poaching of elephants and rhinos. In the 1990s many new projects were launched, including the Living Planet Campaign to produce regular Living Planet Reports on the state of the Earth\'s biodiversity.","By the 2000s much of the work WWF had done over the previous 40 years was showing results. Populations of white rhinos had increased from just 100 to over 11,000, while black rhinos had increased by 30% in just ten years. By 2016 tiger populations were also increasing for the first time in over 100 years.","Despite good news like this, many other species are threatened or in danger of becoming extinct and WWF continues to work on many projects. It\'s reintroducing endangered species like the American bison back into the wild, helping to reduce massive deforestation in places like Borneo and the Amazon, and helping to protect coral reefs and prevent overfishing throughout the world\'s oceans.","WWF also has many educational projects to teach people about urgent issues like climate change, habitat destruction and biodiversity loss. These projects include Earth Hour and Earth Day activities and its Apps For Earth project with Apple Corp. But learning about all these issues can sometimes make us feel sad and lose hope for the future. So WWF has also started online projects to remind us that a bright and sustainable future is still possible if we all work together.","Lalala Demacia.","Testing paragraph as of 25/8"],"_id":"6139f57b410bf19c435a52df","teamId":"61028e57ff2069b3c154c50b","createdAt":"2021-08-21T06:32:11.318Z","updatedAt":"2021-08-29T10:34:37.090Z","__v":0}',REACT_APP_TEAM_SITE_METADATA:'{"template":{"layout":"1","theme":"light"},"publicationOptions":{"groupBy":"None","sortBy":"Year"},"pages":["PUBLICATIONS","TEAM","ACHIEVEMENTS"],"_id":"610657c7fcb589eed677f9d7","teamId":"61028e57ff2069b3c154c50b","createdAt":"2021-08-01T08:13:59.189Z","updatedAt":"2021-09-24T01:50:54.452Z","__v":16,"title":"Kunj Dave","layout":"2","theme":"2"}'});d.REACT_APP_DEBUG?(console.log("Running in DEBUG mode, hence using fake data"),i=[{_id:"fake_publication_1",title:"Auto-icon: An automated code generation tool for icon designs assisting in ui development",description:'"Approximately 50% of development resources are devoted to UI development tasks [8]. Occupied a large proportion of development resources, developing icons can be a time-consuming task, because developers need to consider not only effective implementation methods but also easy-to-understand descriptions. In this study, we define 100 icon classes through an iterative open coding for the existing icon design sharing website. Based on a deep learning model and computer vision methods, we propose an approach to automatically convert icon images to fonts with descriptive labels, thereby reducing the laborious manual effort for developers and facilitating UI development. We quantitatively evaluate the quality of our method in the real world UI development environment and demonstrate that our method offers developers accurate, efficient, readable, and usable code for icon images, in terms of saving 65.2 \u2026',category:{type:"BOOK",categoryTitle:"26th International Conference on Intelligent User Interfaces",issue:"",volume:"",pages:"56-69",publisher:""},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Sidong Feng","Suyu Ma","Jinzhong Yu","Chunyang Chen","TingTing Zhou","Yankun Zhen"],yearPublished:"2021"},{_id:"fake_publication_2",title:"Context-aware Personalized Crowdtesting Task Recommendation",description:"Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker's failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers' perspectives. We motivate this study through a pilot study, revealing the large portion (74%) of unpaid crowdworkers' \u2026",category:{type:"JOURNAL",categoryTitle:"International Economics Journal",issue:"10.1",volume:"11.2",pages:"10",publisher:"IMF"},link:"https://www.imf.org/en/Home",authors:["Jeremy Buffet","Warren Graham"],yearPublished:"2021"},{_id:"fake_publication_3",title:"MULTI-PHACET-MULTIdimensional clinical phenotyping of hospitalised acute COPD ExacerbaTions",description:"Securing generative Arts through NFTs Lorem ipsum amet dolor sit amet, minim altera mucius an eum. Etiam feugiat laoreet tempor. Vestibulum vel facilisis odio, in ultricies ex. Nullam vitae lectus vitae arcu efficitur auctor id a sem. Mauris congue enim risus, eu gravida mi dignissim ut. Vestibulum tempus urna vel sem eleifend, quis aliquet ligula maximus. Vivamus sagittis dolor eu iaculis interdum. Morbi ex odio, ornare eget erat eu, dapibus accumsan elit. Fusce fermentum orci ante. Etiam dolor urna, dictum a diam nec, ornare tempor nunc. Curabitur imperdiet malesuada augue eget vestibulum. Legere antiopam definitiones nam an.",category:{type:"BOOK",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"},{_id:"fake_publication_4",title:"CONCORDANCE OF LARYNGOSCOPY AND DYNAMIC COMPUTERIZED TOMOGRAPHY LARYNX TO DIAGNOSE VOCAL CORD DYSFUNCTION ",description:"",category:{type:"CONFERENCE",categoryTitle:"RESPIROLOGY",issue:"",volume:"",pages:"102-102",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Kaibo Cao","Chunyang Chen","Sebastian Baltes","Christoph Treude","Xiang Chen"],yearPublished:"2017"},{_id:"fake_publication_5",title:"Rivaroxaban compared to placebo for the treatment of leg superficial vein thrombosis: a randomized trial",description:"The role of rivaroxaban in the treatment of leg superficial venous thrombosis (SVT) is uncertain. This article aims to determine if rivaroxaban is an effective and safe treatment for leg SVT. Patients with symptomatic leg SVT of at least 5\u2009cm length were randomized to 45 days of rivaroxaban 10\u2009mg daily or to placebo, and followed for a total of 90 days. Treatment failure (required a nonstudy anticoagulant; had proximal deep vein thrombosis or pulmonary embolism; or had surgery for SVT) at 90 days was the primary efficacy outcome. Secondary efficacy outcomes included leg pain severity, and venous disease-specific and general health-related quality of life over 90 days. Major bleeding at 90 days was the primary safety outcome. Poor enrollment led to the trial being stopped after 85 of the planned 600 patients were randomized to rivaroxaban (n\u2009=\u200943) or placebo (n\u2009=\u200942). One rivaroxaban and five placebo \u2026",category:{type:"OTHER",categoryTitle:"",issue:"",volume:"54",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"},{_id:"fake_publication_6",title:"Owl Eyes: Spotting UI Display Issues via Visual Understanding",description:"Etiam feugiat laoreet tempor. Vestibulum vel facilisis odio, in ultricies ex. Nullam vitae lectus vitae arcu efficitur auctor id a sem. Mauris congue enim risus, eu gravida mi dignissim ut. Vestibulum tempus urna vel sem eleifend, quis aliquet ligula maximus. Vivamus sagittis dolor eu iaculis interdum. Morbi ex odio, ornare eget erat eu, dapibus accumsan elit. Fusce fermentum orci ante. Etiam dolor urna, dictum a diam nec, ornare tempor nunc. Curabitur imperdiet malesuada augue eget vestibulum.  Securing generative Arts through NFTs. Lorem ipsum amet dolor sit amet, minim altera mucius an eum. Legere antiopam definitiones nam an.",category:{type:"CONFERENCE",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio","Yoshua Aenjio","Yoshua Cenjio","Yoshua Denjio","Yoshua Eenjio","Yoshua Fenjio","Yoshua Genjio","Yoshua Henjio","Yoshua Ienjio"],yearPublished:"2017"},{_id:"fake_publication_7",title:"Wireframe-based UI design search through image autoencoder",description:"Securing generative Arts through NFTs",category:{type:"CONFERENCE",categoryTitle:"The digital asset certification",issue:"",volume:"",pages:"15",publisher:"Yoshua Benjio"},link:"thislinkisfakedonteventrytoclickit.okay",authors:["Yoshua Benjio"],yearPublished:"2017"}],n={twitterHandle:"elonmusk",orgName:"Monash",teamName:"MonTeam"},o=[{fullName:"John",position:"Chief Scientist",summary:"John is a chief scientist at MonTeam, working with the top government agencies to fight the pressing issues arising from climate change"},{fullName:"Yoshua Benjio",position:"Chief Data Scientist",summary:"Hailed as one of the founders of Deep Learning, Yoshua works at MonTeam to oversee strategic deep learning project designs"},{fullName:"Jeremy Buffet",position:"Chief Economist",summary:"Jeremy Buffet leads our macro-economic unit in predicting macro factors and their impact on society"}],s={aboutUs:["This is first paragraph.","This is second paragraph.","This is third paragraph."]},r={pages:["PUBLICATIONS","TEAM","ACHIEVEMENTS"],publicationOptions:{layout:"All Publication",sortBy:"Author"},template:{layout:"2",theme:"light"}},l=[{title:"Organisation of The Year",description:"We have been awarded as the Organisation of The Year for 2019",yearAwarded:2019},{title:"Best Team Vibes",description:"We have been awarded for the Best Team Vibes for 2021",yearAwarded:2021},{title:"Most Hardworking Team",description:"We have been awarded as the Most Hardedworking team for 2020",yearAwarded:2020},{title:"Most Dedicated Team",description:"We have been awarded as the Most Dedicated Team for 2020",yearAwarded:2020},{title:"Participation Award",description:"Our efforts have been recognised as we have been awarded the Participation Award for the year 2018. Adding more information to make thi description longer. Adding more information to make thi description longer. Adding more information to make thi description longer. Adding more information to make thi description longer. Adding more information to make thi description longer. Adding more information to make thi description longer.",yearAwarded:2018},{title:"Most Employable Team",description:"We have been awarded as the Most Employable Team for 2019",yearAwarded:2019}]):(i=d.REACT_APP_TEAM_PUBLICATIONS?JSON.parse(d.REACT_APP_TEAM_PUBLICATIONS):[],n=d.REACT_APP_TEAM_INFO?JSON.parse(d.REACT_APP_TEAM_INFO):null,o=d.REACT_APP_TEAM_MEMBERS?JSON.parse(d.REACT_APP_TEAM_MEMBERS):[],s=d.REACT_APP_TEAM_HOMEPAGE?JSON.parse(d.REACT_APP_TEAM_HOMEPAGE):null,r=d.REACT_APP_TEAM_SITE_METADATA?JSON.parse(d.REACT_APP_TEAM_SITE_METADATA):{pages:[],template:{layout:3,theme:"light"},publicationOptions:{layout:"By Category",sortBy:"Category Title"}},l=d.REACT_APP_TEAM_ACHIEVEMENTS?JSON.parse(d.REACT_APP_TEAM_ACHIEVEMENTS):[])},19:function(e,t,a){"use strict";a.r(t);var i=a(0),n=a.n(i),o=a(14),s=a.n(o),r=a(13),l=(a(24),a(25),a(26),a(27),a(12)),d=a(1),c=l.f.template.layout;s.a.render(Object(d.jsx)(r.a,{children:function(){switch(c){case"1":var e=n.a.lazy((function(){return Promise.all([a.e(1),a.e(3)]).then(a.bind(null,18))}));return Object(d.jsx)(d.Fragment,{children:Object(d.jsx)(n.a.Suspense,{fallback:Object(d.jsx)(d.Fragment,{}),children:Object(d.jsx)(e,{})})});case"2":var t=n.a.lazy((function(){return Promise.all([a.e(1),a.e(7)]).then(a.bind(null,36))}));return Object(d.jsx)(d.Fragment,{children:Object(d.jsx)(n.a.Suspense,{fallback:Object(d.jsx)(d.Fragment,{}),children:Object(d.jsx)(t,{})})});case"3":var i=n.a.lazy((function(){return Promise.all([a.e(1),a.e(9),a.e(8)]).then(a.bind(null,37))}));return Object(d.jsx)(d.Fragment,{children:Object(d.jsx)(n.a.Suspense,{fallback:Object(d.jsx)(d.Fragment,{}),children:Object(d.jsx)(i,{})})});default:var o=n.a.lazy((function(){return Promise.all([a.e(1),a.e(3)]).then(a.bind(null,18))}));return Object(d.jsx)(d.Fragment,{children:Object(d.jsx)(n.a.Suspense,{fallback:Object(d.jsx)(d.Fragment,{}),children:Object(d.jsx)(o,{})})})}}()}),document.getElementById("root"))}},[[19,5,6]]]);
//# sourceMappingURL=main.dacc4912.chunk.js.map